\chapter{Conclusions and Outlook}\label{ch:discussion}

The Standard Model of particle physics describes the particles and their interactions through the gauge group $SU(3)_C \times SU(2)_L \times U(1)_Y$ with remarkable precision. However, persistent experimental tensions combined with theoretical challenge provide compelling motivation for physics beyond the SM. These anomalies share a common feature: they suggest new particles with preferential couplings to second and third-generation fermions.

This thesis has presented two phenomenological studies exploring search strategies at the LHC to probe BSM models addressing these anomalies. The first investigates light scalar production in the $U(1)_{T^3_R}$ model through the channel $\mathrm{pp}\to \mathrm{t}\chi_\mathrm{u}\phi'$, demonstrating sensitivity to $\phi'$ masses from $5$ to $325$~GeV and $\chi_\mathrm{u}$ masses up to $2$~TeV at the HL-LHC. The second examines $U_1$ vector leptoquark phenomenology through single, pair, and non-resonant production, showing complete coverage of the $R_{D^{(*)}}$-motivated parameter space for masses up to $5$~TeV. Both analyses employ BDT-based machine learning to maximize signal-background discrimination and profile likelihood methods to quantify discovery potential, demonstrating that carefully designed strategies can significantly extend the reach of LHC experiments into previously inaccessible regions of BSM parameter space.


\section{Summary}

Chapter~\ref{ch:sm} established the theoretical foundation by presenting the SM as a quantum field theory based on the gauge group $SU(3)_C \times SU(2)_L \times U(1)_Y$, and systematically examined its deficiencies. Among the phenomenological challenges, particular emphasis was placed on the anomalies in $B$-meson decays, which suggest violations of lepton flavor universality. The ratios $R_{D^{(*)}} = \mathcal{B}(B \to D^{(*)} \tau \nu_\tau) / \mathcal{B}(B \to D^{(*)} \ell \nu_\ell)$ have been measured by BaBar, Belle, and LHCb to consistently exceed SM predictions. While recent measurements of $R_{K^{(*)}}$ have moved closer to SM predictions, the pattern of earlier deviations, combined with the persistent tension in $R_{D^{(*)}}$, provides strong motivation for considering BSM scenarios with non-universal lepton couplings. These experimental hints share a common feature: they point toward new physics that breaks lepton universality, potentially involving enhanced couplings to heavier fermion generations.

Chapter~\ref{ch:pheno} established the methodological framework employed throughout this thesis, describing the LHC accelerator complex and the multipurpose detectors, explaining particle reconstruction and identification, and introducing the kinematic variables used in collider analyses. The chapter presented the Monte Carlo simulation pipeline that connects theoretical models to experimental observables, consisting of hard-process generation using matrix-element calculations, parton showering and hadronization, and detector simulation. The statistical framework for quantifying analysis sensitivity was developed through likelihood-based hypothesis testing, with the profile likelihood ratio test statistic as the standard method for discriminating between signal-plus-background and background-only hypotheses. Machine learning methods for signal-background discrimination were introduced, with BDTs presented as  multivariate classifiers that can learn complex, non-linear correlations between kinematic variables. This ML-enhanced approach represents a significant advancement over traditional cut-based analyses, particularly in scenarios with low signal-to-background ratios and overlapping kinematic distributions.

In Chapter~\ref{ch:U1T3R}, we investigated the phenomenology of a minimal $U(1)_{T^3_R}$ gauge extension of the SM. This model, motivated by left-right symmetric theories and the embedding of $U(1)_{B-L}$. The model predicts a light scalar boson $\phi'$, with masses potentially below the electroweak scale, and TeV-scale vector-like quarks $\chi_\mathrm{u}$ with QCD couplings. We proposed a search strategy focusing on the previously unexplored production channel $\mathrm{pp}\to \mathrm{t}\chi_\mathrm{u}\phi'$, where the light scalar is produced in association with a heavy top-partner and a SM top quark. The key insight is that the simultaneous production of heavy QCD-coupled particles naturally provides the large momentum required for the decay products of the light $\phi'$ to be efficiently detected in the central regions of the CMS and ATLAS detectors. This ``boosted light particle'' strategy represents a paradigm shift: rather than searching for light scalars through direct low-energy production, we exploit the UV completion of the model by accessing the heavy degrees of freedom that produce the light scalar with substantial transverse momentum.

Our analysis considered the scenario where $\phi'$ has family non-universal couplings and decays primarily to muon pairs ($\phi'\to\mu^+\mu^-$) for $m(\phi') \ge 1$~GeV. The final state signature comprises three muons, a boosted top-quark system, at least one $b$-tagged jet, and large missing transverse momentum. To discriminate this complex signature from SM backgrounds (primarily $\mathrm{t}\bar{\mathrm{t}}\mu^+\mu^-$ and $\mathrm{b}\bar{\mathrm{b}}\mu\mu\mu\nu$), we developed a BDT-based machine learning classifier trained on a broad set of kinematic variables. We also compared the performance of DNNs against BDTs and found that while DNNs achieved marginally better discrimination, the improvement was modest compared to the significantly increased computational cost and training time, making BDTs the more practical choice for this analysis. The classifier output was used in a profile binned-likelihood framework to extract signal significance. The main results demonstrate that the LHC can probe $\phi'$ masses from $5$ to $325$~GeV and $\chi_\mathrm{u}$ masses up to almost $2$~TeV at the HL-LHC with $3000~\mathrm{fb}^{-1}$. This represents a significant extension of the accessible parameter space compared to previous searches. The analysis shows that detection prospects for low-mass particles are substantially enhanced when it is kinematically possible to simultaneously access the heavy degrees of freedom in the UV completion.

Chapter~\ref{ch:vector_lq} focused on the phenomenology of the $U_1$ vector leptoquark, transforming as $({\bf 3},\,{\bf 1},\,2/3)$ under the SM gauge group. This particle is particularly interesting as it represents one of the few viable single-mediator solutions capable of addressing both the $R_{D^{(*)}}$ anomalies in charged-current $B$-meson decays and providing signatures accessible at the LHC. The key feature of this model is that the leptoquark couples preferentially to third-generation fermions through $\mathrm{b}\tau$ and $\mathrm{t}\nu_\tau$ vertices. We developed an analysis strategy combining three complementary production channels: single leptoquark production (sLQ), pair production (dLQ), and non-resonant production (non-res), where the leptoquark mediates $\mathrm{pp}\to\tau^+\tau^-$ processes at the amplitude level. Each channel has distinct sensitivity to the leptoquark mass $M_U$ and its coupling to fermions $g_U$. The single-LQ production cross section scales as $g_U^2$, making it particularly sensitive to the coupling strength, while pair production depends primarily on the QCD couplings and provides model-independent constraints on the mass.

An important aspect of this work was the systematic study of how the chiral structure of the leptoquark couplings affects the phenomenology. We considered three scenarios: exclusive couplings to left-handed currents, mixed chirality, and exclusive right-handed currents. Each scenario predicts different kinematic distributions and different regions of parameter space capable of explaining the $B$-meson anomalies. We found that while the sensitivity is highly dependent on chirality, in all cases the combination of production channels allows for complete coverage of the parameter space. The analysis employed a BDT-based machine learning approach to maximize signal-background discrimination, considering final states with varying $\tau$-lepton and $b$-jet multiplicities. Our results show that the ML approach significantly improves sensitivity compared to traditional cut-based analyses, particularly at large values of $g_U$. The HL-LHC projections indicate complete coverage of the parameter space solving the $B$-anomalies for leptoquark masses up to $5.0$~TeV. An important finding concerns the impact of additional particles predicted by complete gauge theories. We evaluated the effects of a companion $Z'$ boson on non-resonant production and found that interference effects can have considerable impact on the sensitivity regions, depending on the specific masses and couplings.


\section{Methodological insights}

Both studies in this thesis exemplify several key principles in modern collider phenomenology that have broader applicability beyond the specific models investigated:

\paragraph{Machine Learning as a Useful Tool.} Traditional cut-based analyses, while transparent and robust, often fail to fully exploit the information contained in the high-dimensional phase space of LHC events. Both studies demonstrate that machine learning algorithms, particularly BDTs, can learn complex, non-linear correlations between kinematic variables to construct powerful discriminators that significantly enhance sensitivity. The improvements are most pronounced in scenarios with low signal-to-background ratios and overlapping kinematic distributions---precisely the challenging cases where new physics is most likely to remain hidden. The BDT approach allows for optimal use of all available kinematic information simultaneously, rather than imposing sequential cuts that may discard events containing valuable discriminating information in other variables.

\paragraph{Importance of UV Completions.} Both studies in this thesis illustrate a crucial principle: low-energy phenomena and collider signatures are often best understood by considering the full particle spectrum that arises in the UV completion of the theory. The $U(1)_{T^3_R}$ study demonstrates that light particles can be efficiently probed by accessing the heavy degrees of freedom with which they are produced, rather than relying solely on direct low-energy production. The conventional approach of searching for light scalars through direct production may miss important regions of parameter space, while associated production with heavy vector-like quarks naturally provides the boosted kinematics needed for detection. Similarly, the leptoquark study shows that UV completeness introduces additional particles---such as the companion $Z'$ boson in gauge theories---whose presence significantly affects the phenomenology through interference effects in key production channels. In the non-resonant production process, the $Z'$ contributions modify the $\mathrm{pp}\to\tau^+\tau^-$ cross section in regions of parameter space that would otherwise appear most promising for discovery. These interference effects, which depend sensitively on the relative masses and couplings of the leptoquark and $Z'$, can enhance or suppress the signal depending on the specific UV completion.



\paragraph{Complementarity of Search Channels.} Both studies demonstrate that different production mechanisms provide complementary sensitivity to different regions of parameter space. In the $U(1)_{T^3_R}$ case, $\chi_\mathrm{u}$-t fusion and $\chi_\mathrm{u}\bar{\chi}_\mathrm{u}$ production probe different couplings and provide sensitivity across different mass ranges. In the leptoquark case, single, pair, and non-resonant production have different dependencies on $M_U$ and $g_U$, with pair production dominating at low coupling, single production becoming important at intermediate coupling, and non-resonant production providing the strongest constraints at high coupling. Optimal search strategies must consider all relevant channels and their combination, as focusing on a single channel may miss significant portions of the viable parameter space.

\section{Outlook and Future Directions}

The work presented in this thesis opens several avenues for future research, both in extending the current analyses and in exploring related phenomenological questions.

\subsection{Extended Phenomenology of the $U(1)_{T^3_R}$ Model}

\paragraph{Dark Matter in the Neutrino Sector.} The $U(1)_{T^3_R}$ model predicts right-handed neutrinos $\nu_R$ that are required for anomaly cancellation. In certain parameter regimes, the lightest right-handed neutrino could serve as a viable dark matter candidate. A comprehensive study of this scenario would naturally connect collider phenomenology with cosmological observations and dark matter searches. The dark matter properties would be determined by the interplay between the $U(1)_{T^3_R}$ breaking scale, the neutrino mass scale, and the couplings to the new gauge boson $Z'$ and scalar $\phi'$. Constraints would come from multiple fronts: relic abundance calculations requiring the correct thermal freeze-out density, direct detection experiments probing neutrino-nucleon scattering, indirect detection searching for annihilation products in cosmic rays, and collider searches for dark matter production in association with visible particles. The correlations between these different observables could provide a rich phenomenological landscape for testing the model, connecting the LHC signatures studied in this thesis with dark matter experiments and precision cosmology.

\paragraph{Electroweak Precision Tests and $Z'$ Phenomenology.} The $Z'$ gauge boson arising from the spontaneously broken $U(1)_{T^3_R}$ symmetry has not been the primary focus of this thesis but warrants detailed study. The $Z'$ couples to right-handed SM fermions and could contribute to precision electroweak observables through loop corrections, as well as to rare flavor-changing processes. A comprehensive phenomenological program would explore several complementary avenues: precision measurements of $Z$-pole observables constrained by LEP data, contributions to rare processes such as $B_s$-$\bar{B}_s$ mixing and $\mu\to e$ conversion, and direct production at the LHC through Drell-Yan processes $\mathrm{pp} \to Z' \to \ell^+ \ell^-$. Current LHC searches exclude $Z'$ masses below $\sim 4$--$5$~TeV for SM-like couplings, but weaker constraints apply for non-universal couplings characteristic of the $U(1)_{T^3_R}$ model. The interplay between high-energy collider searches and low-energy precision measurements would provide complementary constraints on the $Z'$ mass and coupling strength, with different observables dominating the sensitivity in different regions of parameter space.

\paragraph{$\phi'$ Production in Rare Decays.} While the study in Chapter~\ref{ch:U1T3R} focused on $\phi'$ production in association with vector-like quarks, the dark Higgs could also be produced in rare decays of SM particles if the model allows for appropriate flavor-violating couplings. Two particularly interesting possibilities emerge from the flavor structure of the model. First, if $\phi'$ couples to quarks through mixing with the SM Higgs or through direct Yukawa couplings to vector-like quarks, it could appear in rare $B$ meson decays such as $B \to K\phi'$. When the $\phi'$ subsequently decays to muon pairs, this would produce a distinctive signature with the di-muon invariant mass peaked at $m_{\phi'}$, distinguishing it from the SM process $B \to K \mu^+ \mu^-$. Second, flavor-changing neutral current decays of the top quark mediated by $\phi'$, such as $t \to c \phi'$, could occur at observable rates if the $\phi'$ has flavor-violating couplings. These rare decay processes not only probe the scalar couplings directly but also provide indirect sensitivity to the vector-like fermion sector.


\subsection{Leptoquark Phenomenology Beyond the LHC}

\paragraph{Complementarity with Low-Energy Experiments.} While the LHC provides direct sensitivity to leptoquark masses up to several TeV, low-energy precision experiments offer complementary constraints on the coupling strength. Future $B$-factory experiments such as Belle~II will measure $R_{D^{(*)}}$ with improved precision, potentially confirming or resolving the current $\sim 3\sigma$ tension with SM predictions. Additionally, next-generation experiments searching for charged lepton flavor violation processes such as $\mu\to e\gamma$ and $\mu\to e$ conversion in nuclei will probe parameter regions where leptoquark models typically predict observable effects. A global analysis combining LHC searches, $B$-physics measurements, and charged lepton flavor violation constraints would provide the most comprehensive picture of the allowed parameter space, as the combination of different observables is significantly more powerful than any single measurement.

\paragraph{Future Colliders.} Future colliders would provide complementary sensitivity to leptoquark phenomenology beyond the reach of the HL-LHC. A High-Energy LHC upgrade to $27$~TeV would extend the mass reach to $\sim 3$--$4$~TeV for pair production and potentially above $6$~TeV for single production. A Future Circular Collider at $100$~TeV would probe leptoquark masses up to $\sim 10$--$15$~TeV, entering the boosted regime where specialized reconstruction techniques become necessary. A high-energy muon collider would offer a particularly clean environment for leptoquarks coupling to muons, enabling precision measurements of their properties through both pair and single production channels. Phenomenological studies for these future facilities would be valuable in optimizing their design and understanding the complementarity between different collider options.

\paragraph{Simplified Model Framework.} The leptoquark analysis in Chapter~\ref{ch:vector_lq} considered a specific gauge model with couplings motivated by the $B$-anomalies. A complementary approach would be to develop a simplified model framework that parameterizes leptoquark couplings in a model-independent way, similar to effective field theory approaches. Such a framework would include a minimal set of parameters describing the leptoquark mass, spin, and gauge quantum numbers, along with a general parameterization of couplings to different fermion generations. This would allow experimental collaborations to present results in a way that can be easily reinterpreted across different theoretical models, facilitating comparisons and enabling broader phenomenological studies beyond specific UV-complete theories.

\subsection{Advanced Analysis Techniques}

\paragraph{Tau Polarization Measurements.} In both studies, $\tau$ leptons play important roles in the final states. The polarization of $\tau$ leptons carries information about the chiral structure of the new physics couplings. In the leptoquark study, left-handed and right-handed couplings produce $\tau$ leptons with different polarization states, which in turn affect the kinematics of the visible decay products. Developing machine learning algorithms specifically designed to extract $\tau$ polarization information from the kinematics of hadronic $\tau$ decays could provide an additional discriminating variable to enhance signal sensitivity and to distinguish between different theoretical scenarios.

The $\tau$ polarization can be inferred from the energy fractions carried by the visible decay products in hadronic decays. For example, in the decay $\tau^- \to \pi^- \nu_\tau$, the pion carries a larger fraction of the $\tau$ energy when the $\tau$ is right-handed polarized. More complex decay modes such as $\tau^- \to \rho^- \nu_\tau \to \pi^- \pi^0 \nu_\tau$ provide additional information through the invariant mass and angular distributions of the decay products. Machine learning algorithms, particularly deep neural networks, could be trained to learn the complex correlations between the visible decay products and the initial $\tau$ polarization state, providing a probabilistic polarization measurement for each event.

Such polarization-sensitive analyses would require sophisticated reconstruction of the $\tau$ decay products and careful treatment of the missing neutrino momentum. Recent developments in neural network architectures for particle physics, including attention mechanisms and graph neural networks, could be particularly well-suited for this task. The potential improvement in sensitivity would be most significant in scenarios where different BSM models predict similar production rates and kinematic distributions but differ in their chiral structure.

\paragraph{Attention Mechanisms and Graph Neural Networks.} While BDTs have proven highly effective in both studies presented in this thesis, recent developments in deep learning offer promising alternatives that could provide further improvements. Graph Neural Networks (GNNs) can naturally handle the variable-multiplicity jet and lepton content of LHC events by representing each event as a graph where particles are nodes and their relationships are encoded in edges. This representation is particularly natural for collider events, where the relevant information includes not only the properties of individual particles but also their relationships (e.g., angular separations, invariant masses of pairs).

Attention mechanisms allow the network to dynamically focus on the most relevant features for each event. For example, in the $U(1)_{T^3_R}$ analysis, the network could learn to identify which of the three muons likely originated from the $\phi'$ decay, and which kinematic variables are most discriminating for that particular event topology. This dynamic feature selection could be more powerful than the fixed decision tree structure of BDTs.

These architectures have shown impressive performance in jet tagging tasks, such as distinguishing quark-initiated jets from gluon-initiated jets, and identifying jets from boosted heavy particles. Recent work has also demonstrated their effectiveness in full event classification tasks. Applying these techniques to the searches presented in this thesis could provide incremental improvements in sensitivity, particularly in the most challenging regions of parameter space where signal and background distributions are most similar.

\paragraph{Unbinned Likelihood Methods.} The statistical analyses in this thesis employed binned likelihood approaches, which are standard in high-energy physics but inevitably lose some information through binning. The choice of binning---how many bins to use and where to place the bin boundaries---can affect the final sensitivity. Recent work on unbinned likelihood methods using neural density estimation could provide more powerful hypothesis tests.

These methods use neural networks to learn the full probability density of events in the multidimensional feature space, allowing for optimal statistical inference without binning losses. The network is trained to estimate the likelihood ratio directly, which is the optimal test statistic according to the Neyman-Pearson lemma. This approach could be particularly beneficial in the leptoquark analysis, where the BDT output is binned before performing the likelihood fit. An unbinned approach could extract additional information from the detailed shape of the BDT distribution, potentially improving sensitivity by $10$--$20\%$ in some regions of parameter space.





\subsection{Broader Phenomenological Questions}

\paragraph{Multi-Component New Physics.} Real BSM theories typically predict multiple new particles that can appear simultaneously in LHC events. Future work could explore scenarios where both leptoquarks and $Z'$ bosons, or vector-like quarks and dark Higgs bosons, are produced in the same event. For example:

\begin{itemize}
    \item In the $4321$ model, which contains both leptoquarks and a $Z'$ boson, the process $\mathrm{pp} \to Z' \to \mathrm{LQ} \bar{\mathrm{LQ}}$ could produce leptoquark pairs through $Z'$ mediation. The interference between this process and QCD pair production would depend on the $Z'$ mass and couplings, potentially providing a distinctive signature.
    
    \item In the $U(1)_{T^3_R}$ model, the process $\mathrm{pp} \to \chi_\mathrm{u} \bar{\chi}_\mathrm{u} \to \mathrm{t} \phi' \bar{\mathrm{t}} \phi'$ produces two dark Higgs bosons in the same event. If both decay to muon pairs, the final state would contain four muons, two $b$-jets, and missing energy---a very distinctive signature with low SM background.
\end{itemize}

The interference and correlation effects in such scenarios could provide powerful discrimination between different theoretical frameworks and would require dedicated phenomenological studies to optimize search strategies.

\paragraph{Systematic Uncertainties and Detector Effects.} The phenomenological studies in this thesis included realistic detector effects through Delphes fast simulation but did not explore the full range of systematic uncertainties that would affect experimental analyses. A more detailed treatment would include:

\begin{itemize}
    \item \textbf{Parton distribution function (PDF) uncertainties:} The choice of PDF set and the uncertainties in the parton distributions affect both the signal and background cross sections. These uncertainties are typically evaluated by reweighting events using different PDF sets and can be $5$--$20\%$ depending on the process and kinematic regime.
    
    \item \textbf{Scale variations:} Varying the renormalization and factorization scales by factors of two up and down provides an estimate of missing higher-order corrections. These uncertainties are typically larger for signal processes involving new particles, where next-to-leading-order calculations may not be available.
    
    \item \textbf{Jet energy scale and resolution:} Uncertainties in the jet energy scale and resolution affect the reconstruction of invariant masses and missing transverse energy. These are among the largest experimental systematic uncertainties in many searches and can be $2$--$10\%$ depending on the jet $p_T$ and $\eta$.
    
    \item \textbf{$b$-tagging efficiencies:} Uncertainties in the $b$-tagging efficiency and mistag rates affect searches that rely on identifying $b$-jets. These uncertainties are typically $5$--$15\%$ and are correlated across jets.
    
    \item \textbf{Pileup modeling:} The modeling of additional proton-proton interactions in the same or nearby bunch crossings affects the reconstruction of all objects. This is particularly important for the HL-LHC, where the average number of pileup interactions is expected to reach $\sim 200$.
\end{itemize}

Understanding the impact of these uncertainties on the final sensitivity is important for translating phenomenological projections into experimental search programs. In many cases, systematic uncertainties can be comparable to or larger than statistical uncertainties, particularly at the HL-LHC where the large dataset reduces statistical uncertainties.

\paragraph{Connection to Cosmology.} Many BSM models motivated by collider anomalies also have cosmological implications:

\begin{itemize}
    \item \textbf{Dark matter and structure formation:} The $U(1)_{T^3_R}$ model's right-handed neutrino dark matter candidate could contribute to structure formation. If the dark matter is warm rather than cold (i.e., if it was relativistic at the time of matter-radiation equality), it would suppress structure formation on small scales, potentially resolving tensions between observations and cold dark matter predictions. The warmness depends on the dark matter production mechanism and the reheating temperature after inflation.
    
    \item \textbf{Cosmic microwave background:} New light particles such as the $\phi'$ could contribute to the effective number of relativistic degrees of freedom $N_{\mathrm{eff}}$ at the time of recombination if they were in thermal equilibrium in the early universe. Current measurements from Planck constrain $N_{\mathrm{eff}} = 2.99 \pm 0.17$, consistent with the SM prediction of $3.046$. Future CMB experiments such as CMB-S4 will improve this measurement, potentially detecting contributions from new light particles.
    
    \item \textbf{Leptogenesis:} Leptoquark models with heavy right-handed neutrinos could play a role in leptogenesis, the mechanism for generating the matter-antimatter asymmetry through CP-violating decays of heavy neutrinos. The leptoquark couplings could affect the CP asymmetry and the washout processes, potentially connecting the $B$-anomalies to the baryon asymmetry of the universe.
    
    \item \textbf{Phase transitions:} The spontaneous breaking of $U(1)_{T^3_R}$ could proceed through a first-order phase transition in the early universe, potentially producing gravitational waves detectable by future experiments such as LISA. The phase transition dynamics depend on the scalar potential and the temperature-dependent effective potential.
\end{itemize}

Exploring these connections would strengthen the theoretical motivation for the collider searches and potentially provide additional constraints on the parameter space from cosmological observations.


\section{Closing Remarks}

The Large Hadron Collider has entered a new era with Run~3 and will continue to accumulate data for at least another decade through the High-Luminosity program. The HL-LHC will deliver an unprecedented dataset of $3000~\mathrm{fb}^{-1}$, representing a twenty-fold increase compared to the data collected during Run~1 and Run~2. This enormous dataset offers remarkable opportunities to search for physics beyond the Standard Model, but also presents significant challenges in extracting weak signals from enormous backgrounds.

This thesis has demonstrated that carefully designed phenomenological studies, leveraging modern computational tools including machine learning, are essential for maximizing the discovery potential of the LHC. By identifying optimal search strategies, quantifying sensitivity to specific BSM scenarios, and understanding the interplay between different observables, phenomenological work provides crucial guidance for the experimental program.

The two studies presented here---searching for light scalars in the $U(1)_{T^3_R}$ model and probing vector leptoquarks---represent concrete examples of this approach. Both analyses explore BSM scenarios motivated by persistent experimental anomalies and develop search strategies that could significantly extend the reach of the ATLAS and CMS experiments:

\begin{itemize}
    \item The $U(1)_{T^3_R}$ study demonstrates that the LHC can probe light scalars with masses from $5$ to $325$~GeV by exploiting the UV completion of the theory and producing the scalar in association with heavy vector-like quarks. This strategy provides sensitivity to a mass range that is difficult to access through other means and illustrates the power of considering the full particle spectrum of BSM models.
    
    \item The leptoquark study shows that combining multiple production channels (single, pair, and non-resonant) with machine learning techniques provides comprehensive coverage of the parameter space relevant for explaining the $B$-anomalies. The HL-LHC will be able to probe leptoquark masses up to $5$~TeV for couplings that can address the $R_{D^{(*)}}$ tensions, providing a definitive test of this class of explanations.
\end{itemize}

The methodologies developed in these studies---particularly the application of machine learning for signal-background discrimination, the framework for statistical interpretation, and the systematic exploration of model parameter space---are broadly applicable to other BSM searches. The BDT-based approach has proven effective in both studies, providing significant improvements over traditional cut-based analyses. The extension to more advanced architectures such as graph neural networks and attention mechanisms represents a promising direction for future work.

Beyond the specific results for the $U(1)_{T^3_R}$ and leptoquark models, this thesis contributes to the broader effort of developing and validating phenomenological tools for the LHC era. The Monte Carlo simulation pipeline, the machine learning workflow, and the statistical analysis framework established here can be applied to a wide range of BSM scenarios. The emphasis on considering UV-complete models, exploring the full parameter space, and combining complementary search channels provides a template for future phenomenological studies.

As the LHC continues to probe the energy frontier and Belle~II explores the intensity frontier, the coming years promise to be an exciting time for particle physics. The experimental anomalies that motivated this work---particularly the $R_{D^{(*)}}$ tensions and the muon $(g-2)$ discrepancy---will be measured with increasing precision. Whether these experiments discover new particles or further constrain the parameter space of BSM models, the result will advance our understanding of nature's fundamental laws.

If the anomalies persist and are confirmed with higher significance, the searches proposed in this thesis will be among the most promising avenues for discovering the responsible new particles at the LHC. The $U(1)_{T^3_R}$ model provides a framework that can simultaneously address multiple anomalies while predicting distinctive signatures, and the leptoquark explanation of $R_{D^{(*)}}$ remains one of the most compelling single-mediator solutions. The phenomenological studies presented here demonstrate that these scenarios are testable at the LHC, particularly with the HL-LHC dataset.

If, on the other hand, the anomalies disappear with more data, the searches developed here will still provide valuable constraints on BSM scenarios with non-universal lepton couplings. The techniques developed---particularly the machine learning approaches and the combination of multiple production channels---will remain relevant for other BSM searches. The emphasis on considering the full particle spectrum of UV-complete theories and the importance of interference effects will continue to be important lessons for phenomenological studies.

The phenomenological tools and strategies developed in this thesis contribute to the ongoing quest to discover physics beyond the Standard Model, bridging the gap between theoretical ideas and experimental reality, and helping to ensure that if new physics exists within the reach of current experiments, we will find it. The search for physics beyond the Standard Model is far from over. The path forward requires continued synergy between theory, phenomenology, and experiment, with each discipline informing and challenging the others. It is in this collaborative spirit that the work presented in this thesis is offered as a contribution to the collective effort to unravel the mysteries that the Standard Model leaves unanswered.

The next decade of LHC operations will be decisive. With the HL-LHC dataset, we will either discover new particles that explain the observed anomalies, or we will constrain BSM scenarios to the point where new experimental approaches or higher-energy colliders become necessary. The phenomenological studies presented in this thesis demonstrate that the LHC has the potential to make transformative discoveries if we employ optimal search strategies and leverage the full power of modern computational techniques. The future of particle physics depends on this combination of theoretical insight, phenomenological innovation, and experimental precision.
